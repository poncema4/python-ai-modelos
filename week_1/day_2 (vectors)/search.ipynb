{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsqueda vectorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('embeddings/peliculas_text-embedding-3-small-1536.json') as f:\n",
    "    movies = json.load(f)\n",
    "\n",
    "MODEL_DIMENSIONS = 1536 # Must match the dimension of the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar el OpenAI client con GitHub Models\n",
    "\n",
    "Ejecuta la celda de abajo si estás utilizando OpenAI con GitHub Models. Si estás ejecutando esto en GitHub Codespaces, la variable de entorno GITHUB_TOKEN ya estará configurada para ti. Si estás ejecutando esto localmente, asegúrate de configurar la variable de entorno GITHUB_TOKEN con un Token de Acceso Personal (PAT) de GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai_client = openai.OpenAI(\n",
    "    base_url=\"https://models.github.ai/inference\",\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"]\n",
    ")\n",
    "MODEL_NAME = \"openai/text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar el OpenAI client con modelos de Azure OpenAI\n",
    "\n",
    "Ejecuta la celda de abajo si estás utilizando Azure OpenAI keyless auth y ya has configurado un archivo .env con las variables requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "azure_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(azure_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "openai_client = OpenAI(\n",
    "    base_url=os.getenv(\"AZURE_OPENAI_ENDPOINT\") + \"/openai/v1/\",\n",
    "    api_key=token_provider,\n",
    ")\n",
    "MODEL_NAME = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defina la función para generar un embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    embeddings_response = openai_client.embeddings.create(\n",
    "        model=MODEL_NAME,\n",
    "        dimensions=MODEL_DIMENSIONS,\n",
    "        input=text,\n",
    "    )\n",
    "    return embeddings_response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busqueda de embeddings vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    dot_product = sum([a * b for a, b in zip(v1, v2)])\n",
    "    magnitude = (sum([a**2 for a in v1]) * sum([a**2 for a in v2])) ** 0.5\n",
    "    return dot_product / magnitude\n",
    "\n",
    "def exhaustive_search(query_vector, vectors):\n",
    "    similarities = []\n",
    "    for title, vector in vectors.items():\n",
    "        similarity = cosine_similarity(query_vector, vector)\n",
    "        similarities.append((title, similarity))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities\n",
    "\n",
    "new_vector = get_embedding(\"una pelicula apta para ninos acerca de animales\")\n",
    "similarities = exhaustive_search(new_vector, movies)\n",
    "most_similar = similarities[0:10]\n",
    "similar_movies = [(movie, round(similarity, 3)) for movie, similarity in most_similar]\n",
    "\n",
    "pd.DataFrame(similar_movies, columns=['pelicula', 'similitud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda ANN: HNSW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "\n",
    "# Declarando índice\n",
    "p = hnswlib.Index(space='cosine', dim=1536)\n",
    "\n",
    "# Inicializando índice - el número máximo de elementos debe conocerse de antemano\n",
    "p.init_index(max_elements=len(movies), ef_construction=200, M=16)\n",
    "\n",
    "# Inserción de elementos (puede ser llamada varias veces):\n",
    "vectors = list(movies.values())\n",
    "ids = list([i for i in range(len(vectors))])\n",
    "p.add_items(vectors, ids)\n",
    "\n",
    "# Controlando la recuperación mediante el ajuste de ef:\n",
    "p.set_ef(50) # ef siempre debe ser > k\n",
    "\n",
    "### Los parámetros del índice se exponen como propiedades de clase:\n",
    "print(f\"Parámetros pasados al constructor:  space={p.space}, dim={p.dim}\") \n",
    "print(f\"Construcción del índice: M={p.M}, ef_construction={p.ef_construction}\")\n",
    "print(f\"El tamaño del índice es {p.element_count} y la capacidad del índice es {p.max_elements}\")\n",
    "print(f\"Parámetro de equilibrio entre velocidad/calidad de búsqueda: ef={p.ef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar en el índice HNSW\n",
    "new_vector = get_embedding(\"una pelicula apta para ninos acerca de gatos\")\n",
    "\n",
    "labels, distances = p.knn_query(new_vector, k=10)\n",
    "\n",
    "# asociar etiquetas con títulos de películas y mostrarlos\n",
    "similar_movies = [(list(movies.keys())[label], round(1 - distance, 3)) for label, distance in zip(labels[0], distances[0])]\n",
    "pd.DataFrame(similar_movies, columns=['película', 'similitud'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
